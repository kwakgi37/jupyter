{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e572d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "식물 영역의 녹색 비율: 12887.09%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 이미지 파일을 읽어옵니다.\n",
    "image = cv2.imread('test3.jpg')\n",
    "\n",
    "# 이미지 크기를 800x600으로 조절합니다.\n",
    "resized_image = cv2.resize(image, (800, 600))\n",
    "\n",
    "# YOLOv3 모델을 로드하고 설정합니다.\n",
    "net = cv2.dnn.readNet('darknet-master/cfg/yolov3.weights', 'darknet-master/cfg/yolov3.cfg')\n",
    "\n",
    "# 클래스 목록을 로드합니다 (예: COCO 클래스 목록).\n",
    "with open('darknet-master/data/coco.names', 'r') as f:\n",
    "    classes = [line.strip().lower() for line in f]\n",
    "\n",
    "# 이미지를 blob 형식으로 변환합니다.\n",
    "blob = cv2.dnn.blobFromImage(resized_image, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# 모델에 blob을 입력으로 전달하고 객체 감지를 수행합니다.\n",
    "net.setInput(blob)\n",
    "outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    "# 감지된 객체 중에서 가장 확률이 높은 객체의 식별자를 가져옵니다.\n",
    "conf_threshold = 0.5\n",
    "class_id = None\n",
    "max_confidence = 0\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > max_confidence and confidence > conf_threshold:\n",
    "            max_confidence = confidence\n",
    "\n",
    "# 가장 확률이 높은 객체의 좌표를 가져옵니다.\n",
    "if class_id is not None:\n",
    "    center_x = int(detection[0] * resized_image.shape[1])\n",
    "    center_y = int(detection[1] * resized_image.shape[0])\n",
    "    w = int(detection[2] * resized_image.shape[1])\n",
    "    h = int(detection[3] * resized_image.shape[0])\n",
    "    \n",
    "    # 객체의 ROI를 추출합니다. ROI가 이미지를 벗어나지 않도록 보정합니다.\n",
    "    x1, y1 = max(center_x - w // 2, 0), max(center_y - h // 2, 0)\n",
    "    x2, y2 = min(center_x + w // 2, resized_image.shape[1]), min(center_y + h // 2, resized_image.shape[0])\n",
    "    plant_roi = resized_image[y1:y2, x1:x2]\n",
    "\n",
    "    # 추출한 ROI를 이용하여 녹색 비율을 계산합니다.\n",
    "    hsv_roi = cv2.cvtColor(plant_roi, cv2.COLOR_BGR2HSV)\n",
    "    green_channel = hsv_roi[:, :, 1]\n",
    "    green_pixels = np.sum(green_channel)\n",
    "    total_pixels = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    # 녹색 비율을 계산합니다.\n",
    "    green_ratio = (green_pixels / total_pixels)\n",
    "    print(\"식물 영역의 녹색 비율: {:.2%}\".format(green_ratio))\n",
    "\n",
    "    # 바운딩 박스를 표시합니다.\n",
    "    cv2.rectangle(resized_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # 이미지를 표시합니다.\n",
    "    cv2.imshow('Detected Plant', resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"객체를 감지하지 못했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b815e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "식물 영역의 녹색 비율: 4651.64%\n",
      "가장 확률이 높은 객체의 식별자: 0\n",
      "객체의 좌표 (x, y, w, h): 0.9875896 0.9907605 0.16737755 0.020364404\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 이미지 파일을 읽어옵니다.\n",
    "image = cv2.imread('pl.jpg')\n",
    "\n",
    "# 이미지 크기를 800x600으로 조절합니다.\n",
    "resized_image = cv2.resize(image, (800, 600))\n",
    "\n",
    "# YOLOv3 모델을 로드하고 설정합니다.\n",
    "net = cv2.dnn.readNet('darknet-master/cfg/yolov3.weights', 'darknet-master/cfg/yolov3.cfg')\n",
    "\n",
    "# 클래스 목록을 로드합니다 (예: COCO 클래스 목록).\n",
    "with open('darknet-master/data/coco.names', 'r') as f:\n",
    "    classes = [line.strip().lower() for line in f]\n",
    "\n",
    "# 이미지를 blob 형식으로 변환합니다.\n",
    "blob = cv2.dnn.blobFromImage(resized_image, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# 모델에 blob을 입력으로 전달하고 객체 감지를 수행합니다.\n",
    "net.setInput(blob)\n",
    "outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    "# 감지된 객체 중에서 가장 확률이 높은 객체의 식별자를 가져옵니다.\n",
    "conf_threshold = 0.5\n",
    "class_id = None\n",
    "max_confidence = 0\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > max_confidence and confidence > conf_threshold:\n",
    "            max_confidence = confidence\n",
    "\n",
    "# 가장 확률이 높은 객체의 좌표를 가져옵니다.\n",
    "if class_id is not None:\n",
    "    center_x = int(detection[0] * resized_image.shape[1])\n",
    "    center_y = int(detection[1] * resized_image.shape[0])\n",
    "    w = int(detection[2] * resized_image.shape[1])\n",
    "    h = int(detection[3] * resized_image.shape[0])\n",
    "    \n",
    "    # 객체의 ROI를 추출합니다. ROI가 이미지를 벗어나지 않도록 보정합니다.\n",
    "    x1, y1 = max(center_x - w // 2, 0), max(center_y - h // 2, 0)\n",
    "    x2, y2 = min(center_x + w // 2, resized_image.shape[1]), min(center_y + h // 2, resized_image.shape[0])\n",
    "    plant_roi = resized_image[y1:y2, x1:x2]\n",
    "\n",
    "    # 추출한 ROI를 이용하여 녹색 비율을 계산합니다.\n",
    "    hsv_roi = cv2.cvtColor(plant_roi, cv2.COLOR_BGR2HSV)\n",
    "    green_channel = hsv_roi[:, :, 1]\n",
    "    green_pixels = np.sum(green_channel)\n",
    "    total_pixels = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    # 녹색 비율을 계산합니다.\n",
    "    green_ratio = (green_pixels / total_pixels)\n",
    "    print(\"식물 영역의 녹색 비율: {:.2%}\".format(green_ratio))\n",
    "\n",
    "    # 바운딩 박스와 객체 정보를 표시합니다.\n",
    "    print(\"가장 확률이 높은 객체의 식별자:\", class_id)\n",
    "    print(\"객체의 좌표 (x, y, w, h):\", detection[0], detection[1], detection[2], detection[3])\n",
    "\n",
    "    # 바운딩 박스를 표시합니다.\n",
    "    cv2.rectangle(resized_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # 이미지를 표시합니다.\n",
    "    cv2.imshow('Detected Plant', resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"객체를 감지하지 못했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595121dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
